base_path: "/Users/mischa/Projects/local/dragtor/data/"
expose_library_logs: False # allows to use loguru for external loggers

data:
  cache_dir: "cached/"
  jina_urls:
    - "https://www.hoopersbeta.com/library/a2-pulley-manual-for-climbers"
    - "https://www.hoopersbeta.com/library/weight-training-and-rock-climbing"
    - "https://www.hoopersbeta.com/library/how-to-heal-from-a-lumbrical-injury-5-simple-stages-to-recover"
    - "https://www.hoopersbeta.com/library/flexor-tenosynovitis"
    - "https://www.hoopersbeta.com/library/will-hangboarding-2x/day-improve-your-climbing-ultimate-revised-breakdown"    
  audio_urls:
     # - "https://cdn-media.huggingface.co/speech_samples/sample2.flac"
    - "https://cdn.simplecast.com/audio/8d0e41cc-be61-4d71-ab0d-b985db72bb92/episodes/42685a36-6381-4017-ad34-48fe1822e83e/audio/2c2a3b1c-7b39-4852-a947-6f7ea10dbf98/default_tc.mp3"

chunking:
  # valid strategies: paragraph [default], jina_tokenizer, recursive_char
  strategy: recursive_char
  jina_tokenizer:
    max_chunk_length: 1000
  langchain_tokenizer:
    max_chunk_length: 1000
    chunk_overlap: 50

embeddings:
  # valid strategies: chromadb [default], jina
  strategy: jina
  jina:
    device: mps
    # max length: 8192
    max_seq_length: 512

store:
  # valid strategies: chromadb [default]
  strategy: default
  n_query: 10
  chromadb:
    path: chroma_db
    collection_name: main_collection
    # valid distances: l2, ip, cosine
    distance: cosine

reranker:
  # valid strategies: dummy [default], jina
  strategy: jina
  n_ranked: 5

index:
  # valid strategies: basic [default], late_chunking
  strategy: default

# LLM model configuration
model:
  # host: 127.0.0.1
  # port: 8080
  file_path: "/Users/mischa/Projects/local/dragtor/models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf"
  max_completion_tokens: 2048
  kwargs:
    gpu-layers: 15
    ctx-size: 15000

# Prompts configuration
prompts:
  system: >
    You are an assistant who provides advice on health care and training questions for climbers.
    You answer questions in 3 paragraphs.
  user_template: |
    Please use the following pieces of context to answer the question.
    context:

    {context}

    question:
    {question}

    answer:

server:
  backoff: 1.0

eval:
  eval_dir: "eval/"
  eval_answers: "gold_answers.json"

audio:
  model: "/Users/mischa/Projects/local/dragtor/models/ggml-base.en.bin"
  lang: "en"

# Paths to external projects containing executables
executables:
  llama_project: "/Users/mischa/Projects/local/llama-cpp/llama.cpp"
  whisper_project: "/Users/mischa/Projects/local/whisper.cpp"
